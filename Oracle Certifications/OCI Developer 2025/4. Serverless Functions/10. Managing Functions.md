Resiliency and availability are paramount in ensuring the uninterrupted operation of systems even in the face of failures or degraded performance. In the context of OCI Functions, resiliency refers to system's capability to withstand disruptions, while availability signifies its ability to remain accessible to users.

OCI Functions prioritizes resiliency and high availability by distributing its Control and Data Plane components across multiple availability domains and fault domains within a region. This distributed architecture ensures that if one domain experiences an outage, the system can seamlessly switch to alternative domains to maintain uninterrupted function management and execution.

When invoking functions, it's essential to adhere to best practices to optimize resiliency and availability. Designating a regional subnet for an application or leveraging multiple availability domain-specific subnets enhances fault tolerance and ensures continuous function execution even during domain failures.

Concurrency refers to a system's capability to run multiple operations simultaneously using shared resources. Scalability, on the other hand, is the ability of a system to adjust its capacity, both increasing and decreasing to match the demand.

OCI Functions excels in handling multiple simultaneous requests through automatic horizontal scaling. When multiple calls are made to a running function, OCI functions efficiently starts additional containers to handle the load, up to a limit specified for your tenancy. By default, this limit is 60 GB of RAM reserved for function execution per availability domain.

Another crucial aspect is the isolation of function executions. When functions from different applications are invoked concurrently, OCI Functions ensures that each function runs in isolation from others. This isolation prevents any interference between function executions, maintaining a secure and efficient environment for all running functions.

Next, let's discuss reducing initial latency using provisioned concurrency. When a function is invoked for the first time, often referred to as cold start, OCI Functions provisions, the function invocation with the necessary execution infrastructure. This includes the compute and network resources required for the function to execute successfully. The initial provisioning and response to this first invocation might take a variable amount of time, potentially several seconds or longer. However, once the infrastructure is in place, subsequent function invocations, also known as hot starts, can make use of existing infrastructure. This typically results in a subsecond response time to the function invocation. To ensure that the execution infrastructure required for a function is always available and to minimize any latency associated with initial provisioning, OCI Functions supports provisioned concurrency. Provisioned concurrency allows OCI Functions to always have the necessary execution infrastructure ready for a certain minimum number of concurrent function invocation. This is measured in Provisioned Concurrency Units or PCUs.
To use provisioned concurrency effectively, you need to specify the number of provisioned concurrency units or PCUs required for your function. It's generally a good practice to match the number of PCUs to the number of concurrent function invocations you anticipate.