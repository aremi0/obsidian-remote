se i container crashano, upgrade o rollback delle applicazioni, scaling up o scaling down dei container across machines, queste operazioni e molte altre possono essere automatizzate tramite un containerization engine come kubernetes.

k8s infatti è una piattaforma open source e portable per l'orchestrazione dei container, raggruppandoli all'interno di unità logiche e automatizzando lo scaling of workloads.

come è strutturato k8s?

in k8s vi è un master node che gestisci molteplici worker node, ogni worker node può gestire molteplici pods. Un pods è un insieme di container clusterizzati assieme come unica working unit logica.
Quindi si comincia a disegnare una applicazione usando i pods, ovvero i cluster di container di tipo A, B, C (uno per ogni servizio che si vuole prevedere nell'applicazione), una volta che i pod sono pronti ci si interfaccia con il master node diversi aspetti come il numero di di quanti container si vogliono deployare e la definizione dei pod. Da questo momento k8s entra in controllo, prende i pod e li deploya nei worker node in base alla loro (dei worker node) availability e load status, tutto in maniera trasparente allo sviluppatore devops.

